{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqQHV6l_4ekX"
   },
   "source": [
    "# **k-Plus Proches Voisins**\n",
    "\n",
    "Documentation Sci-kit Learn sur les k-Nearest Neighbours : https://scikit-learn.org/stable/modules/neighbors.html\n",
    "\n",
    "# Méthodes des plus proches voisins\n",
    "\n",
    "Le principe des méthodes des plus proches voisins est de trouver un nombre prédéfini d'échantillons d'entraînement les plus proches en distance d'un nouveau point, puis de prédire son étiquette à partir de ces échantillons. Le nombre d'échantillons peut être une constante définie par l'utilisateur (**apprentissage des k plus proches voisins**) ou varier en fonction de la densité locale des points (**apprentissage basé sur un rayon**). La distance utilisée peut être toute mesure métrique ; la distance euclidienne standard est le choix le plus courant.\n",
    "\n",
    "Les méthodes basées sur les voisins sont connues comme des méthodes d'apprentissage non généralisantes, car elles « mémorisent » simplement toutes les données d'entraînement.\n",
    "\n",
    "Malgré sa simplicité, l'algorithme des plus proches voisins a été utilisé avec succès dans de nombreux problèmes de classification et de régression, notamment la reconnaissance de chiffres manuscrits et l'analyse d'images satellites. Étant une méthode non paramétrique, elle est souvent efficace dans des situations où la frontière de décision est très irrégulière.\n",
    "\n",
    "![K-Nearest Neighbours](https://scikit-learn.org/stable/_images/sphx_glr_plot_nca_classification_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXeBu4eq4eka"
   },
   "source": [
    "# Importer les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt # visualisation des données\n",
    "import pandas as pd  # traitement des données (ex: lecture de fichiers CSV)\n",
    "import seaborn as sns # visualisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BFQOSgx4ekb"
   },
   "source": [
    "# Importer le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrJtnlFz6U3E"
   },
   "outputs": [],
   "source": [
    "# importer le jeu de données du cancer du sein avec sklearn\n",
    "breast_cancer = load_breast_cancer(as_frame=True)\n",
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJLd_RSAi7xe"
   },
   "source": [
    "# Jeu de données vers DataFrame Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ih7mFYmhCNDR"
   },
   "outputs": [],
   "source": [
    "# Mettre les données dans un dataframe pandas avec la variable cible (que nous essaierons de prédire) comme dernière colonne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJSErP5_CNDR"
   },
   "outputs": [],
   "source": [
    "# First 10 value of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbg972974ekd"
   },
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBSCv4e6CNDR"
   },
   "outputs": [],
   "source": [
    "# Forme du jeu de données (nb de lignes et de colonnes)\n",
    "\n",
    "# Nom des colonnes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jsLdS3nhCNDS"
   },
   "outputs": [],
   "source": [
    "# Print dataset info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhUKWzN44ekd"
   },
   "outputs": [],
   "source": [
    "# Description of the dataset (mean, std, min, max, quartiles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2mm4Azy4ekf"
   },
   "source": [
    "### Distribution de fréquence des valeurs dans les variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GclPxZVZCNDT"
   },
   "outputs": [],
   "source": [
    "# Names of the target values\n",
    "\n",
    "\n",
    "# Count of each target value\n",
    "\n",
    "\n",
    "# Comme ci-dessus mais en pourcentage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS1GyY1q4ekf"
   },
   "source": [
    "We can see that the dataset is balanced in terms of its classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdVH_bC_4ekf"
   },
   "source": [
    "### Valeurs manquantes dans les variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3Vu_Mfb4ekg"
   },
   "outputs": [],
   "source": [
    "# Number of missing values in each column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSLsEjdxi7xg"
   },
   "source": [
    "## Correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1jA_IIBBi7xg"
   },
   "outputs": [],
   "source": [
    "# Correlation matrix between all the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQ30nl3oi7xg"
   },
   "outputs": [],
   "source": [
    "# Heatmap of the correlation matrix\n",
    "\n",
    "\n",
    "# Annot = True to print the values inside the square\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcthNPrCi7xh"
   },
   "outputs": [],
   "source": [
    "# afficher les variables les plus corrélées avec la variable cible (valeur absolue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBsSCiCki7xh"
   },
   "source": [
    "### Tracer quelques données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHuesECci7xh"
   },
   "outputs": [],
   "source": [
    "# converting the data into categorical\n",
    "\n",
    "\n",
    "# Plot the 2 most correlated features with the target variable\n",
    "\n",
    "\n",
    "# converting the data back into numerical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGYMZnTTi7xh"
   },
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test séparés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ycc6bxAyi7xh"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Diviser le jeu de données en ensembles d'entraînement et de test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lfe370fYi7xh"
   },
   "outputs": [],
   "source": [
    "# Check the shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-HTRRvSi7xi"
   },
   "outputs": [],
   "source": [
    "# Print number of unique values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9aO0kmai7xi"
   },
   "source": [
    "# Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9D8z_ykDi7xi"
   },
   "outputs": [],
   "source": [
    "# check data types in X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgTHGKXEi7xi"
   },
   "source": [
    "All data is numerical, so we don't need to do any encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEUk8fiHi7xi"
   },
   "source": [
    "# K-Nearest Neighbours Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPwxHq4IvNa"
   },
   "source": [
    "<!-- Add an image link in markdown in a smaller size: -->\n",
    "![knn](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/220px-KnnClassification.svg.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHUWth0ai7xi"
   },
   "outputs": [],
   "source": [
    "# Create a KNN classifier with 8 neighbors\n",
    "\n",
    "\n",
    "# Entraîner le modèle en utilisant les ensembles d'entraînement\n",
    "\n",
    "\n",
    "# Précision du modèle sur l'ensemble d'entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8y2a2GXi7xj"
   },
   "outputs": [],
   "source": [
    "# Predict the response for test dataset\n",
    "\n",
    "\n",
    "# Accuracy of the model on the testing set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wws5UoKJi7xj"
   },
   "source": [
    "## Plot the accuracy of the model on training and testing set for different k neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3M2XQgZi7xj"
   },
   "outputs": [],
   "source": [
    "\n",
    "# try n_neighbors from 1 to 15\n",
    "\n",
    "\n",
    "    # Create a KNN classifier with 8 neighbors\n",
    "\n",
    "\n",
    "    # Entraîner le modèle en utilisant les ensembles d'entraînement\n",
    "\n",
    "\n",
    "    # Précision du modèle sur l'ensemble d'entraînement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DP3z3a3fi7xj"
   },
   "source": [
    "# Rapport de classification\n",
    "\n",
    "**Le rapport de classification** est un autre moyen d'évaluer les performances du modèle de classification. Il affiche les scores de **précision**, **rappel**, **f1** et **support** pour le modèle. J'ai décrit ces termes plus loin.\n",
    "\n",
    "We can print a classification report as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0dtsOpui7xj"
   },
   "outputs": [],
   "source": [
    "# Plot the classification report for k=8\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvrUuRvKi7xj"
   },
   "source": [
    "# Matrice de confusion\n",
    "\n",
    "Une matrice de confusion aide à résumer les performances d'un algorithme de classification. Elle donne une image claire de la performance d'un modèle de classification ainsi que des types d'erreurs produites par celui-ci. <br>\n",
    "Elle donne un résumé des prédictions correctes et incorrectes réparties par catégorie. \n",
    "\n",
    "\n",
    "Quatre types de résultats sont possibles lors de l'évaluation des performances d'un modèle de classification :\n",
    "\n",
    "\n",
    "**Vrais Positifs (VP)** – Nous prédisons qu'une observation appartient à une certaine classe *x* et l'observation appartient effectivement à cette classe *x*.\n",
    "\n",
    "\n",
    "**Vrais Négatifs (VN)** – Nous prédisons qu'une observation n'appartient pas à une certaine classe *x* et l'observation n'appartient effectivement pas à cette classe *x*.\n",
    "\n",
    "\n",
    "**Faux Positifs (FP)** – Nous prédisons qu'une observation appartient à une certaine classe *x* mais l'observation **n'appartient pas** à cette classe *x*. Ce type d'erreur est appelé erreur de Type I.\n",
    "\n",
    "\n",
    "\n",
    "**Faux Négatifs (FN)** – Nous prédisons qu'une observation n'appartient pas à une certaine classe *x* mais l'observation **appartient effectivement** à cette classe *x*. C'est une erreur très grave appelée erreur de Type II.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccXZHDzei7xk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2XrlUaxi7xk"
   },
   "source": [
    "# Validation croisée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkKV1PP6i7xk"
   },
   "outputs": [],
   "source": [
    "# Validation croisée avec 5 découpes différentes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoALGdh2i7xk"
   },
   "source": [
    "# ROC and AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBVCLDJtIvNc"
   },
   "source": [
    "The ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_f-2LHXi7xk"
   },
   "outputs": [],
   "source": [
    "# Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4-GURasIvNc"
   },
   "source": [
    "# Decision Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKCySYQIIvNc"
   },
   "source": [
    "Decision Boundaries shows the decision regions of the classifier. It is a line or a curve that separates the decision regions of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLTXS2N7i7xk"
   },
   "outputs": [],
   "source": [
    "# Print decision boundary for KNN classifier over the most correlated features\n",
    "\n",
    "# Decision boundary for worst concave points vs worst perimeter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aV3Brn8Hi7xl"
   },
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x90__uYLi7xl"
   },
   "source": [
    "Principal Component Analysis is a dimensionality reduction technique. It is used to reduce the number of features in a dataset. It is used to reduce the complexity of the model and to reduce the training time. It is also used to visualise high dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLdHsV7Ki7xl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FiOyAgDi7xl"
   },
   "source": [
    "# Références : \n",
    "1. https://scikit-learn.org/\n",
    "2. https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "3. https://www.kaggle.com/code/prashant111/knn-classifier-tutorial"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
